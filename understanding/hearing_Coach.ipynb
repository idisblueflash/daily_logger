{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hearing Coach\n",
    "Use Deep Learnling to help me improve understanding about textbook with dictation method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = open('passage.txt','r')\n",
    "sentences = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Quick Theory Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(sentences)):\n",
    "    for word in sentences[i].split(\" \"):\n",
    "        total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 47),\n",
       " ('to', 20),\n",
       " ('a', 19),\n",
       " ('', 17),\n",
       " ('of', 15),\n",
       " ('gradient', 12),\n",
       " ('in', 12),\n",
       " ('change', 9),\n",
       " ('node', 9),\n",
       " ('with', 9),\n",
       " ('cost', 8),\n",
       " ('can', 7),\n",
       " ('this', 6),\n",
       " ('We', 6),\n",
       " ('for', 6),\n",
       " ('how', 6),\n",
       " ('is', 6),\n",
       " ('we', 6),\n",
       " ('that', 5),\n",
       " ('it', 5),\n",
       " ('blame', 5),\n",
       " ('on', 4),\n",
       " ('C.', 4),\n",
       " ('you', 4),\n",
       " ('w2', 4),\n",
       " ('respect', 4),\n",
       " ('and', 4),\n",
       " ('gradients', 4),\n",
       " ('value', 3),\n",
       " ('calculate', 3),\n",
       " ('update', 3),\n",
       " ('into', 3),\n",
       " ('more', 3),\n",
       " ('by', 3),\n",
       " ('l2', 3),\n",
       " ('out', 3),\n",
       " ('cost.', 3),\n",
       " ('each', 3),\n",
       " ('linear', 3),\n",
       " ('weights', 3),\n",
       " ('want', 3),\n",
       " ('need', 3),\n",
       " ('see', 3),\n",
       " ('larger', 3),\n",
       " ('l2,', 3),\n",
       " ('these', 3),\n",
       " ('much', 3),\n",
       " (\"we'll\", 3),\n",
       " ('an', 3),\n",
       " ('then', 2),\n",
       " ('gradient,', 2),\n",
       " ('steepest', 2),\n",
       " ('learning_rate', 2),\n",
       " ('chain', 2),\n",
       " ('network.', 2),\n",
       " ('x', 2),\n",
       " ('*', 2),\n",
       " ('gradx', 2),\n",
       " ('way,', 2),\n",
       " ('The', 2),\n",
       " ('gets', 2),\n",
       " ('our', 2),\n",
       " ('descent', 2),\n",
       " ('which', 2),\n",
       " ('using', 2),\n",
       " ('node,', 2),\n",
       " (\"Let's\", 2),\n",
       " ('second', 2),\n",
       " ('values', 2),\n",
       " ('And', 2),\n",
       " ('In', 2),\n",
       " ('assign', 2),\n",
       " ('node.', 2),\n",
       " ('will', 2),\n",
       " ('eventually', 2),\n",
       " ('direction', 2),\n",
       " ('Gradient', 2),\n",
       " ('make', 2),\n",
       " ('Backpropagation', 2),\n",
       " ('w2.', 2),\n",
       " ('so', 2),\n",
       " ('Multiplying', 2),\n",
       " ('going', 2),\n",
       " ('affected', 2),\n",
       " ('For', 2),\n",
       " ('total', 1),\n",
       " ('application', 1),\n",
       " ('given', 1),\n",
       " ('layer', 1),\n",
       " ('as', 1),\n",
       " ('consider', 1),\n",
       " ('yourself', 1),\n",
       " ('calculus.', 1),\n",
       " ('creates', 1),\n",
       " ('initially', 1),\n",
       " ('forwards', 1),\n",
       " ('updates', 1),\n",
       " ('biases', 1),\n",
       " ('write', 1),\n",
       " ('cost,', 1),\n",
       " ('math', 1),\n",
       " ('nodes', 1),\n",
       " ('figure', 1),\n",
       " ('MSE', 1),\n",
       " ('another', 1),\n",
       " ('graph', 1),\n",
       " ('between', 1),\n",
       " ('pass', 1),\n",
       " ('minimum', 1),\n",
       " ('MiniFlow,', 1),\n",
       " ('You', 1),\n",
       " ('lessons', 1),\n",
       " ('what', 1),\n",
       " ('sigmoid', 1),\n",
       " ('based', 1),\n",
       " ('followed', 1),\n",
       " ('weights.', 1),\n",
       " ('sure', 1),\n",
       " ('slope,', 1),\n",
       " ('produces', 1),\n",
       " ('∂C', 1),\n",
       " ('rule:', 1),\n",
       " ('all', 1),\n",
       " ('would', 1),\n",
       " ('look', 1),\n",
       " ('Remember', 1),\n",
       " ('converge', 1),\n",
       " ('C', 1),\n",
       " ('like:', 1),\n",
       " ('flows', 1),\n",
       " ('old', 1),\n",
       " ('w2:', 1),\n",
       " ('changes', 1),\n",
       " ('Forward', 1),\n",
       " ('simple', 1),\n",
       " ('final', 1),\n",
       " ('determines', 1),\n",
       " ('behind', 1),\n",
       " ('attributed', 1),\n",
       " ('from', 1),\n",
       " ('contribute', 1),\n",
       " ('backpropagation', 1),\n",
       " ('learning_rate.', 1),\n",
       " ('two', 1),\n",
       " ('Continuing', 1),\n",
       " ('ascent', 1),\n",
       " ('find', 1),\n",
       " (\"we're\", 1),\n",
       " ('gradx.', 1),\n",
       " ('video', 1),\n",
       " ('Now', 1),\n",
       " ('create', 1),\n",
       " ('l2.', 1),\n",
       " ('Solution', 1),\n",
       " ('turns', 1),\n",
       " (\"it's\", 1),\n",
       " ('subtracting', 1),\n",
       " ('This', 1),\n",
       " ('C,', 1),\n",
       " ('finally,', 1),\n",
       " ('means,', 1),\n",
       " ('adjust', 1),\n",
       " ('Accordingly,', 1),\n",
       " ('force', 1),\n",
       " ('Subtracting', 1),\n",
       " ('getting', 1),\n",
       " ('together', 1),\n",
       " ('Descent', 1),\n",
       " ('checking', 1),\n",
       " ('multivariable', 1),\n",
       " ('Writing', 1),\n",
       " ('connected', 1),\n",
       " ('example,', 1),\n",
       " ('have', 1),\n",
       " ('Below', 1),\n",
       " ('those', 1),\n",
       " ('relationship', 1),\n",
       " ('Another', 1),\n",
       " ('sending', 1),\n",
       " ('know', 1),\n",
       " ('just', 1),\n",
       " ('nodes.', 1),\n",
       " ('s,', 1),\n",
       " ('replacing', 1),\n",
       " ('refresher,', 1),\n",
       " ('l1\\u200b\\u200b,', 1),\n",
       " ('derivatives', 1),\n",
       " ('produce', 1),\n",
       " ('back', 1),\n",
       " ('Pre-requisites', 1),\n",
       " ('If', 1),\n",
       " ('First', 1),\n",
       " ('highly', 1),\n",
       " ('l\\u200b2', 1),\n",
       " (\"Academy's\", 1),\n",
       " ('goes', 1),\n",
       " ('step.', 1),\n",
       " ('I', 1),\n",
       " ('descent,', 1),\n",
       " ('requires', 1),\n",
       " ('∂l2.', 1),\n",
       " ('framework', 1),\n",
       " ('one', 1),\n",
       " ('subtraction', 1),\n",
       " ('Khan', 1),\n",
       " ('So', 1),\n",
       " ('has,', 1),\n",
       " ('&', 1),\n",
       " ('partial', 1),\n",
       " ('network', 1),\n",
       " ('use', 1),\n",
       " ('pushing', 1),\n",
       " ('layer,', 1),\n",
       " ('rule', 1),\n",
       " ('addition.', 1),\n",
       " ('descent.', 1),\n",
       " ('recommend', 1),\n",
       " ('through', 1)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n"
     ]
    }
   ],
   "source": [
    "vocab = set(total_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '&': 206,\n",
       " '*': 49,\n",
       " \"Academy's\": 184,\n",
       " 'Accordingly,': 141,\n",
       " 'And': 127,\n",
       " 'Another': 165,\n",
       " 'Backpropagation': 198,\n",
       " 'Below': 160,\n",
       " 'C': 83,\n",
       " 'C,': 142,\n",
       " 'C.': 42,\n",
       " 'Continuing': 112,\n",
       " 'Descent': 150,\n",
       " 'First': 213,\n",
       " 'For': 212,\n",
       " 'Forward': 7,\n",
       " 'Gradient': 190,\n",
       " 'I': 34,\n",
       " 'If': 181,\n",
       " 'In': 134,\n",
       " 'Khan': 200,\n",
       " \"Let's\": 98,\n",
       " 'MSE': 35,\n",
       " 'MiniFlow,': 43,\n",
       " 'Multiplying': 75,\n",
       " 'Now': 119,\n",
       " 'Pre-requisites': 179,\n",
       " 'Remember': 79,\n",
       " 'So': 201,\n",
       " 'Solution': 125,\n",
       " 'Subtracting': 144,\n",
       " 'The': 56,\n",
       " 'This': 133,\n",
       " 'We': 71,\n",
       " 'Writing': 145,\n",
       " 'You': 44,\n",
       " 'a': 41,\n",
       " 'addition.': 78,\n",
       " 'adjust': 139,\n",
       " 'affected': 76,\n",
       " 'all': 69,\n",
       " 'an': 192,\n",
       " 'and': 183,\n",
       " 'another': 36,\n",
       " 'application': 4,\n",
       " 'as': 10,\n",
       " 'ascent': 113,\n",
       " 'assign': 140,\n",
       " 'attributed': 102,\n",
       " 'back': 31,\n",
       " 'backpropagation': 107,\n",
       " 'based': 53,\n",
       " 'behind': 100,\n",
       " 'between': 84,\n",
       " 'biases': 26,\n",
       " 'blame': 124,\n",
       " 'by': 128,\n",
       " 'calculate': 19,\n",
       " 'calculus.': 14,\n",
       " 'can': 110,\n",
       " 'chain': 120,\n",
       " 'change': 64,\n",
       " 'changes': 91,\n",
       " 'checking': 151,\n",
       " 'connected': 155,\n",
       " 'consider': 11,\n",
       " 'contribute': 106,\n",
       " 'converge': 82,\n",
       " 'cost': 116,\n",
       " 'cost,': 29,\n",
       " 'cost.': 55,\n",
       " 'create': 122,\n",
       " 'creates': 17,\n",
       " 'derivatives': 30,\n",
       " 'descent': 67,\n",
       " 'descent,': 188,\n",
       " 'descent.': 217,\n",
       " 'determines': 95,\n",
       " 'direction': 185,\n",
       " 'each': 48,\n",
       " 'eventually': 173,\n",
       " 'example,': 157,\n",
       " 'figure': 5,\n",
       " 'final': 96,\n",
       " 'finally,': 21,\n",
       " 'find': 114,\n",
       " 'flows': 86,\n",
       " 'followed': 57,\n",
       " 'for': 73,\n",
       " 'force': 143,\n",
       " 'forwards': 24,\n",
       " 'framework': 195,\n",
       " 'from': 103,\n",
       " 'gets': 61,\n",
       " 'getting': 208,\n",
       " 'given': 8,\n",
       " 'goes': 186,\n",
       " 'going': 207,\n",
       " 'gradient': 58,\n",
       " 'gradient,': 6,\n",
       " 'gradients': 216,\n",
       " 'gradx': 51,\n",
       " 'gradx.': 117,\n",
       " 'graph': 163,\n",
       " 'has,': 205,\n",
       " 'have': 158,\n",
       " 'highly': 182,\n",
       " 'how': 123,\n",
       " 'in': 159,\n",
       " 'initially': 22,\n",
       " 'into': 27,\n",
       " 'is': 138,\n",
       " 'it': 88,\n",
       " \"it's\": 174,\n",
       " 'just': 168,\n",
       " 'know': 167,\n",
       " 'l1\\u200b\\u200b,': 175,\n",
       " 'l2': 46,\n",
       " 'l2,': 148,\n",
       " 'l2.': 99,\n",
       " 'larger': 136,\n",
       " 'layer': 9,\n",
       " 'layer,': 214,\n",
       " 'learning_rate': 16,\n",
       " 'learning_rate.': 108,\n",
       " 'lessons': 33,\n",
       " 'like:': 85,\n",
       " 'linear': 93,\n",
       " 'look': 74,\n",
       " 'l\\u200b2': 152,\n",
       " 'make': 197,\n",
       " 'math': 194,\n",
       " 'means,': 137,\n",
       " 'minimum': 40,\n",
       " 'more': 37,\n",
       " 'much': 154,\n",
       " 'multivariable': 153,\n",
       " 'need': 126,\n",
       " 'network': 209,\n",
       " 'network.': 18,\n",
       " 'node': 111,\n",
       " 'node,': 81,\n",
       " 'node.': 177,\n",
       " 'nodes': 32,\n",
       " 'nodes.': 170,\n",
       " 'of': 161,\n",
       " 'old': 87,\n",
       " 'on': 23,\n",
       " 'one': 196,\n",
       " 'our': 65,\n",
       " 'out': 50,\n",
       " 'partial': 72,\n",
       " 'pass': 39,\n",
       " 'produce': 178,\n",
       " 'produces': 63,\n",
       " 'pushing': 211,\n",
       " 'recommend': 115,\n",
       " 'refresher,': 172,\n",
       " 'relationship': 164,\n",
       " 'replacing': 105,\n",
       " 'requires': 189,\n",
       " 'respect': 135,\n",
       " 'rule': 215,\n",
       " 'rule:': 66,\n",
       " 's,': 171,\n",
       " 'second': 104,\n",
       " 'see': 132,\n",
       " 'sending': 166,\n",
       " 'sigmoid': 52,\n",
       " 'simple': 203,\n",
       " 'slope,': 62,\n",
       " 'so': 204,\n",
       " 'steepest': 15,\n",
       " 'step.': 187,\n",
       " 'subtracting': 130,\n",
       " 'subtraction': 199,\n",
       " 'sure': 60,\n",
       " 'that': 38,\n",
       " 'the': 92,\n",
       " 'then': 2,\n",
       " 'these': 149,\n",
       " 'this': 3,\n",
       " 'those': 162,\n",
       " 'through': 156,\n",
       " 'to': 193,\n",
       " 'together': 147,\n",
       " 'total': 1,\n",
       " 'turns': 129,\n",
       " 'two': 109,\n",
       " 'update': 20,\n",
       " 'updates': 25,\n",
       " 'use': 210,\n",
       " 'using': 77,\n",
       " 'value': 13,\n",
       " 'values': 121,\n",
       " 'video': 118,\n",
       " 'w2': 94,\n",
       " 'w2.': 202,\n",
       " 'w2:': 89,\n",
       " 'want': 101,\n",
       " 'way,': 54,\n",
       " 'we': 169,\n",
       " \"we'll\": 180,\n",
       " \"we're\": 97,\n",
       " 'weights': 80,\n",
       " 'weights.': 59,\n",
       " 'what': 45,\n",
       " 'which': 68,\n",
       " 'will': 146,\n",
       " 'with': 176,\n",
       " 'would': 70,\n",
       " 'write': 28,\n",
       " 'x': 47,\n",
       " 'you': 131,\n",
       " 'yourself': 12,\n",
       " '∂C': 90,\n",
       " '∂l2.': 191}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    word2index[word] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('through', 0), ('descent.', 0), ('gradients', 0), ('addition.', 0)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_learned_counter = Counter()\n",
    "\n",
    "for word in vocab:\n",
    "    word_learned_counter[word] = 0\n",
    "\n",
    "list(reversed(word_learned_counter.most_common()))[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def speak_out(text):\n",
    "    subprocess.call([\"say\", text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_a_new_word():\n",
    "    word_waiting_list = list(reversed(word_learned_counter.most_common()))\n",
    "    for word, cnt in word_waiting_list:\n",
    "        # print('Debug: word', word)\n",
    "        if (cnt == 0):\n",
    "            return word\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Checking for words understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  words left. 0.0 %\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    current_word = get_a_new_word()\n",
    "    speak_out(current_word)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "new_words = 0\n",
    "for word, cnt in list(reversed(word_learned_counter.most_common())):\n",
    "    if (cnt == 0):\n",
    "        new_words += 1\n",
    "print (new_words , \n",
    "       ' words left.', \n",
    "       100 * new_words/len(word_learned_counter.most_common()),\n",
    "      '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer is: \n"
     ]
    }
   ],
   "source": [
    "print('Answer is:', current_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 1),\n",
       " ('total', 1),\n",
       " ('then', 1),\n",
       " ('application', 1),\n",
       " ('gradient,', 1),\n",
       " ('given', 1),\n",
       " ('layer', 1),\n",
       " ('as', 1),\n",
       " ('consider', 1),\n",
       " ('yourself', 1)]"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add points in word\n",
    "word_learned_counter[current_word] +=1\n",
    "list(word_learned_counter.most_common())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gradients', -1), ('rule', -1), ('For', -1), ('affected', -1)]"
      ]
     },
     "execution_count": 787,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substract points in word\n",
    "word_learned_counter[current_word] -=1\n",
    "list(reversed(word_learned_counter.most_common()))[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('total', 1),\n",
       " ('then', 1),\n",
       " ('application', 1),\n",
       " ('gradient,', 1),\n",
       " ('given', 1),\n",
       " ('layer', 1),\n",
       " ('as', 1),\n",
       " ('consider', 1),\n",
       " ('yourself', 1),\n",
       " ('value', 1),\n",
       " ('steepest', 1),\n",
       " ('learning_rate', 1),\n",
       " ('values', 1),\n",
       " ('network.', 1),\n",
       " ('calculate', 1),\n",
       " ('finally,', 1),\n",
       " ('initially', 1),\n",
       " ('on', 1),\n",
       " ('forwards', 1),\n",
       " ('updates', 1),\n",
       " ('into', 1),\n",
       " ('back', 1),\n",
       " ('framework', 1),\n",
       " ('lessons', 1),\n",
       " ('MSE', 1),\n",
       " ('another', 1),\n",
       " ('more', 1),\n",
       " ('that', 1),\n",
       " ('graph', 1),\n",
       " ('between', 1),\n",
       " ('turns', 1),\n",
       " ('a', 1),\n",
       " ('MiniFlow,', 1),\n",
       " ('You', 1),\n",
       " ('what', 1),\n",
       " ('each', 1),\n",
       " ('x', 1),\n",
       " ('*', 1),\n",
       " ('gradx', 1),\n",
       " ('based', 1),\n",
       " ('way,', 1),\n",
       " ('cost.', 1),\n",
       " ('gradient', 1),\n",
       " ('weights.', 1),\n",
       " ('sure', 1),\n",
       " ('gets', 1),\n",
       " ('slope,', 1),\n",
       " ('change', 1),\n",
       " ('our', 1),\n",
       " ('∂C', 1),\n",
       " ('l2', 1),\n",
       " ('rule:', 1),\n",
       " ('which', 1),\n",
       " ('We', 1),\n",
       " ('for', 1),\n",
       " ('using', 1),\n",
       " ('Remember', 1),\n",
       " ('node,', 1),\n",
       " ('converge', 1),\n",
       " ('like:', 1),\n",
       " ('it', 1),\n",
       " ('w2:', 1),\n",
       " ('changes', 1),\n",
       " ('linear', 1),\n",
       " ('w2.', 1),\n",
       " ('Forward', 1),\n",
       " ('force', 1),\n",
       " ('final', 1),\n",
       " ('l2.', 1),\n",
       " ('behind', 1),\n",
       " ('l2,', 1),\n",
       " ('want', 1),\n",
       " ('from', 1),\n",
       " ('backpropagation', 1),\n",
       " ('learning_rate.', 1),\n",
       " ('can', 1),\n",
       " ('node', 1),\n",
       " ('Continuing', 1),\n",
       " ('find', 1),\n",
       " ('cost', 1),\n",
       " ('gradx.', 1),\n",
       " ('video', 1),\n",
       " ('Now', 1),\n",
       " ('chain', 1),\n",
       " ('create', 1),\n",
       " ('how', 1),\n",
       " (\"Let's\", 1),\n",
       " ('blame', 1),\n",
       " ('Solution', 1),\n",
       " ('need', 1),\n",
       " ('And', 1),\n",
       " ('by', 1),\n",
       " ('l1\\u200b\\u200b,', 1),\n",
       " ('subtracting', 1),\n",
       " ('you', 1),\n",
       " ('followed', 1),\n",
       " ('In', 1),\n",
       " ('respect', 1),\n",
       " ('larger', 1),\n",
       " ('update', 1),\n",
       " ('means,', 1),\n",
       " ('is', 1),\n",
       " ('adjust', 1),\n",
       " ('Accordingly,', 1),\n",
       " ('C,', 1),\n",
       " ('Subtracting', 1),\n",
       " ('getting', 1),\n",
       " ('w2', 1),\n",
       " ('together', 1),\n",
       " ('old', 1),\n",
       " ('Descent', 1),\n",
       " ('checking', 1),\n",
       " ('multivariable', 1),\n",
       " ('produce', 1),\n",
       " ('nodes', 1),\n",
       " ('Writing', 1),\n",
       " ('much', 1),\n",
       " ('connected', 1),\n",
       " ('will', 1),\n",
       " ('example,', 1),\n",
       " ('have', 1),\n",
       " ('in', 1),\n",
       " ('Below', 1),\n",
       " ('of', 1),\n",
       " ('those', 1),\n",
       " ('relationship', 1),\n",
       " ('Another', 1),\n",
       " ('so', 1),\n",
       " ('sending', 1),\n",
       " ('know', 1),\n",
       " ('just', 1),\n",
       " ('we', 1),\n",
       " ('nodes.', 1),\n",
       " ('second', 1),\n",
       " ('refresher,', 1),\n",
       " ('eventually', 1),\n",
       " ('with', 1),\n",
       " ('node.', 1),\n",
       " ('cost,', 1),\n",
       " ('If', 1),\n",
       " ('layer,', 1),\n",
       " ('highly', 1),\n",
       " ('and', 1),\n",
       " ('direction', 1),\n",
       " ('goes', 1),\n",
       " ('step.', 1),\n",
       " ('I', 1),\n",
       " ('descent,', 1),\n",
       " ('requires', 1),\n",
       " ('Gradient', 1),\n",
       " ('an', 1),\n",
       " ('math', 1),\n",
       " ('one', 1),\n",
       " ('make', 1),\n",
       " ('Backpropagation', 1),\n",
       " ('subtraction', 1),\n",
       " ('Khan', 1),\n",
       " ('So', 1),\n",
       " ('simple', 1),\n",
       " ('has,', 1),\n",
       " ('&', 1),\n",
       " ('would', 1),\n",
       " ('going', 1),\n",
       " ('network', 1),\n",
       " ('use', 1),\n",
       " ('pushing', 1),\n",
       " ('First', 1),\n",
       " ('addition.', 1),\n",
       " ('descent.', 1),\n",
       " ('through', 1),\n",
       " ('', -1),\n",
       " ('figure', -1),\n",
       " ('calculus.', -1),\n",
       " ('creates', -1),\n",
       " ('biases', -1),\n",
       " ('derivatives', -1),\n",
       " ('this', -1),\n",
       " ('pass', -1),\n",
       " ('minimum', -1),\n",
       " ('C.', -1),\n",
       " ('out', -1),\n",
       " ('sigmoid', -1),\n",
       " ('see', -1),\n",
       " ('The', -1),\n",
       " ('produces', -1),\n",
       " ('descent', -1),\n",
       " ('all', -1),\n",
       " ('partial', -1),\n",
       " ('Multiplying', -1),\n",
       " ('C', -1),\n",
       " ('flows', -1),\n",
       " ('the', -1),\n",
       " ('determines', -1),\n",
       " ('weights', -1),\n",
       " ('attributed', -1),\n",
       " ('replacing', -1),\n",
       " ('contribute', -1),\n",
       " ('two', -1),\n",
       " ('ascent', -1),\n",
       " ('recommend', -1),\n",
       " ('This', -1),\n",
       " ('assign', -1),\n",
       " ('these', -1),\n",
       " ('s,', -1),\n",
       " (\"it's\", -1),\n",
       " ('write', -1),\n",
       " ('look', -1),\n",
       " ('Pre-requisites', -1),\n",
       " (\"we'll\", -1),\n",
       " ('l\\u200b2', -1),\n",
       " (\"Academy's\", -1),\n",
       " ('∂l2.', -1),\n",
       " ('to', -1),\n",
       " (\"we're\", -1),\n",
       " ('affected', -1),\n",
       " ('For', -1),\n",
       " ('rule', -1),\n",
       " ('gradients', -1)]"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_learned_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence_demo = \"In this way, the gradient descent updates we make will eventually converge to the minimum of the cost.\"\n",
    "\n",
    "def evaluate_sentence(sentence):\n",
    "    words = sentence.split(\" \")\n",
    "    understand_total = []\n",
    "    for word in words:\n",
    "        understand_total.append(word_learned_counter[word])\n",
    "    return np.mean(understand_total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22222222222222221"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_sentence('In this way, the gradient descent updates we make will eventually converge to the minimum of the cost.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 806,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_sentence('We adjust the old x pushing it in the direction of gradx with the force learning_rate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 1\n",
      "1 1.0 3\n",
      "3 1.0 4\n",
      "35 1.0 2\n",
      "4 0.666666666667 24\n",
      "10 0.642857142857 28\n",
      "2 0.625 16\n",
      "27 0.6 15\n",
      "31 0.6 10\n",
      "25 0.575757575758 33\n",
      "5 0.571428571429 14\n",
      "17 0.565217391304 23\n",
      "15 0.538461538462 13\n",
      "6 0.5 4\n",
      "11 0.5 8\n",
      "33 0.5 4\n",
      "16 0.454545454545 11\n",
      "20 0.411764705882 17\n",
      "21 0.411764705882 17\n",
      "18 0.391304347826 23\n",
      "30 0.384615384615 13\n",
      "26 0.375 16\n",
      "14 0.363636363636 22\n",
      "12 0.333333333333 9\n",
      "24 0.333333333333 12\n",
      "34 0.333333333333 6\n",
      "19 0.285714285714 14\n",
      "8 0.28 25\n",
      "22 0.28 25\n",
      "36 0.272727272727 11\n",
      "23 0.238095238095 21\n",
      "9 0.222222222222 18\n",
      "7 0.2 30\n",
      "13 0.2 20\n",
      "28 0.0 12\n",
      "32 0.0 6\n",
      "29 -1.0 1\n"
     ]
    }
   ],
   "source": [
    "sentence_predict_count = Counter()\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    sentence_predict_count[i] = evaluate_sentence(sentences[i])\n",
    "\n",
    "sentence_predict_count.most_common()\n",
    "for sentence_id, predict in list(sentence_predict_count.most_common()):\n",
    "    sentence_len = 0\n",
    "    for word in sentences[sentence_id].split(\" \"):\n",
    "        sentence_len += 1\n",
    "    print(sentence_id, predict, sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = 27\n",
    "speak_out(sentences[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you need a refresher, I highly recommend checking out\n"
     ]
    }
   ],
   "source": [
    "print(sentences[test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# todo\n",
    "# 1. all lowercase\n",
    "# 2. save it on disk with 腌制\n",
    "# 3. more func for update words_learned and sentences_learned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
